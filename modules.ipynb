{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./modules/pairwise.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./modules/pairwise.py\n",
    "\n",
    "import importlib\n",
    "\n",
    "class PairwiseModel():\n",
    "\n",
    "    @classmethod\n",
    "    def fit(cls, data):\n",
    "\n",
    "        module_name = \"sklearn.metrics.pairwise\"\n",
    "        module = importlib.import_module(module_name)\n",
    "        func = getattr(module, cls.metric)\n",
    "\n",
    "        results = func(data.iloc[0:1], data.iloc[:]).argsort()[0][-6:-1]\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./modules/model_euclidean.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./modules/model_euclidean.py\n",
    "\n",
    "from modules.pairwise import PairwiseModel\n",
    "\n",
    "class Model(PairwiseModel):\n",
    "    NAME = 'distance_model'\n",
    "    MODEL_LIBRARIES = {'scikit-learn': '0.24.1'}\n",
    "    FEATURES = 'pairwise'\n",
    "    metric = 'euclidean_distances'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./modules/model_cosine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./modules/model_cosine.py\n",
    "\n",
    "from modules.pairwise import PairwiseModel\n",
    "\n",
    "class Model(PairwiseModel):\n",
    "    NAME = 'similarity_model'\n",
    "    MODEL_LIBRARIES = {'scikit-learn': '0.24.1'}\n",
    "    FEATURES = 'pairwise'\n",
    "    metric = 'cosine_similarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./modules/table_utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./modules/table_utils.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return val  # return the original value if it can not be evaluated\n",
    "\n",
    "def import_data(text_user_movies, csv_user_tmdb_data, csv_popular_movies_tmdb_data):\n",
    "    with open(text_user_movies) as f:\n",
    "        movies = f.read().splitlines()\n",
    "        \n",
    "    user_tmdb_data = pd.read_csv(csv_user_tmdb_data, converters={'genres': safe_literal_eval})\n",
    "\n",
    "    popular_movies_tmdb_data = pd.read_csv(csv_popular_movies_tmdb_data, converters={'genres': safe_literal_eval})\n",
    "    already_seen_movies = list((set(popular_movies_tmdb_data['movie_id']).intersection(movies)))\n",
    "    popular_movies_tmdb_data = popular_movies_tmdb_data[~popular_movies_tmdb_data['movie_id'].str.contains('|'.join(already_seen_movies))]\n",
    "    \n",
    "    return user_tmdb_data, popular_movies_tmdb_data\n",
    "\n",
    "def get_user_preferred_genre(user_data):\n",
    "\n",
    "    genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "    'Thriller', 'TV Movie', 'War', 'Western']\n",
    "\n",
    "    one_hot_genres = user_data['genres'].str.join('|').str.get_dummies()\n",
    "\n",
    "    difference = list((set(genres).difference(one_hot_genres)))\n",
    "\n",
    "    if len(difference) > 0:\n",
    "        for genre in difference :\n",
    "            one_hot_genres[genre] = 0\n",
    "            # print(genre + ' added !')\n",
    "        one_hot_genres = one_hot_genres[genres]\n",
    "    else:\n",
    "        # print('Nothing added !')\n",
    "        one_hot_genres = one_hot_genres[genres]\n",
    "        \n",
    "    most_preferred_genre_array = np.where(one_hot_genres.sum()*2 > one_hot_genres.sum().max(), 1,0)\n",
    "    user_preferred_genre = pd.DataFrame([most_preferred_genre_array], columns=genres)\n",
    "\n",
    "    return user_preferred_genre\n",
    "\n",
    "def get_user_preferred_decade(user_data):\n",
    "\n",
    "    user_data['decade'] = user_data['year_released'] - user_data['year_released'].astype(str).str[-1].astype(int)\n",
    "\n",
    "    most_preferred_decade = user_data['decade'].value_counts().idxmax()\n",
    "    user_preferred_decade = pd.DataFrame([most_preferred_decade], columns=['decade'])\n",
    "\n",
    "    return user_preferred_decade\n",
    "\n",
    "def get_user_preferred_language(user_data):\n",
    "\n",
    "    most_preferred_lang = user_data['original_language'].value_counts().idxmax()\n",
    "    user_preferred_language = pd.DataFrame([most_preferred_lang], columns=['original_language'])\n",
    "\n",
    "    return user_preferred_language\n",
    "\n",
    "def get_user_preferred_length(user_data):\n",
    "\n",
    "    most_preferred_length = int(user_data['runtime'].mean())\n",
    "    user_preferred_length = pd.DataFrame([most_preferred_length], columns=['runtime'])\n",
    "\n",
    "    return user_preferred_length\n",
    "\n",
    "def get_user_reconstituted_overview(user_data):\n",
    "\n",
    "    # Ignoring stopwords (words with no semantics) from English\n",
    "    stopwords_list = stopwords.words('english')\n",
    "\n",
    "    # Initialize a TF-IDF Vectorizer whose vectors size is 5000 and\n",
    "    # composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                        ngram_range=(1, 2),\n",
    "                        min_df=0.003,\n",
    "                        max_df=0.5,\n",
    "                        max_features=5000,\n",
    "                        stop_words=stopwords_list)\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(user_data['overview']) # fit and transform overviews\n",
    "    tfidf_feature_names = vectorizer.get_feature_names_out() # get feature names from the transformed vectorizer\n",
    "\n",
    "    df = pd.DataFrame(tfidf_matrix.toarray(), columns = tfidf_feature_names) # gather data and feature names\n",
    "\n",
    "    # Keep the 50 best tokens\n",
    "    top_50_overview_tokens = df.sum().reset_index(None).rename(columns={'index':'token', 0:'tfidf_sum'}).sort_values(by='tfidf_sum', ascending=False).head(50)\n",
    "\n",
    "    # Reconstitute an overview based on the best tokens\n",
    "    most_relevant_tokens = ' '.join(top_50_overview_tokens['token'])\n",
    "    user_reconstituted_overview = pd.DataFrame([most_relevant_tokens], columns=['overview'])\n",
    "\n",
    "    return user_reconstituted_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from modules.table_utils import (\n",
    "    get_user_preferred_genre, \n",
    "    get_user_preferred_decade, \n",
    "    get_user_preferred_language, \n",
    "    get_user_preferred_length, \n",
    "    get_user_reconstituted_overview\n",
    ")\n",
    "class FeatureEncoder():\n",
    "\n",
    "    NAME = 'pairwise'\n",
    "    \n",
    "    @classmethod\n",
    "    def preprocess(cls, user_tmdb_data, popular_movies_tmdb_data):\n",
    "        \n",
    "        user_movie_id = pd.DataFrame(['user-profile-recsys'], columns=['movie_id']) \n",
    "        user_preferred_decade = get_user_preferred_decade(user_tmdb_data)\n",
    "        user_reconstituted_overview = get_user_reconstituted_overview(user_tmdb_data)\n",
    "        user_preferred_length = get_user_preferred_length(user_tmdb_data)\n",
    "        user_preferred_language = get_user_preferred_language(user_tmdb_data)\n",
    "        user_preferred_genre = get_user_preferred_genre(user_tmdb_data)\n",
    "\n",
    "        user_profile = pd.concat([user_movie_id, user_preferred_decade, user_reconstituted_overview, user_preferred_length, user_preferred_language, user_preferred_genre], axis=1)\n",
    "        \n",
    "        popular_movies_tmdb_data = popular_movies_tmdb_data.dropna(subset=['overview']).copy() # drop rows with NaN values in the overview column\n",
    "        \n",
    "        popular_movies_tmdb_data['decade'] = popular_movies_tmdb_data['year_released'] - popular_movies_tmdb_data['year_released'].astype(str).str[-1].astype(int)\n",
    "\n",
    "        genres = ['Action', 'Adventure', 'Animation', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'History', 'Horror', 'Music', 'Mystery', 'Romance', 'Science Fiction',\n",
    "        'Thriller', 'TV Movie', 'War', 'Western']\n",
    "\n",
    "        one_hot_genres = popular_movies_tmdb_data['genres'].str.join('|').str.get_dummies()\n",
    "\n",
    "        difference = list((set(genres).difference(one_hot_genres)))\n",
    "\n",
    "        if len(difference) > 0:\n",
    "            for genre in difference :\n",
    "                one_hot_genres[genre] = 0\n",
    "                # print(genre + ' added !')\n",
    "            one_hot_genres = one_hot_genres[genres]\n",
    "        else:\n",
    "            # print('Nothing added !')\n",
    "            one_hot_genres = one_hot_genres[genres]\n",
    "            \n",
    "        one_hot_genres\n",
    "\n",
    "        popular_movies = pd.concat([popular_movies_tmdb_data[['movie_id', 'decade', 'overview', 'runtime', 'original_language']], one_hot_genres], axis=1)\n",
    "        \n",
    "        concat_data = pd.concat([user_profile, popular_movies], axis=0)\n",
    "        data = concat_data.reset_index(drop=True)\n",
    "\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        doc_vec = tfidf_vectorizer.fit_transform(data.iloc[:,2]) # overview text tf-idf\n",
    "        \n",
    "        label_encoder = LabelEncoder()\n",
    "        data['decade'] = label_encoder.fit_transform(data['decade'])\n",
    "        \n",
    "        \n",
    "        original_language = data['original_language'].str.get_dummies()\n",
    "        \n",
    "        data = pd.concat([data, original_language], axis=1)\n",
    "        \n",
    "        movie_ids = data['movie_id'].to_dict()\n",
    "        \n",
    "        data = data.drop(['movie_id', 'overview', 'original_language'], axis=1)\n",
    "        \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        data = pd.DataFrame(min_max_scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "        return {\n",
    "            'data': data,\n",
    "            'movie_ids': movie_ids\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from modules import init, MODELS, MODEL_LIBRARIES, FEATURES\n",
    "init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'distance_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.table_utils import import_data\n",
    "\n",
    "user_tmdb_data, popular_movies_tmdb_data = import_data('./data/user_movies.txt', './data/user_tmdb_data.csv', './data/popular_movies_tmdb_data.csv')\n",
    "\n",
    "model = MODELS[name]\n",
    "\n",
    "encoder = FEATURES.get(model.FEATURES)\n",
    "res = encoder.preprocess(user_tmdb_data, popular_movies_tmdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n_rec = model.fit(res['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['howls-moving-castle',\n",
       " 'klaus',\n",
       " 'godzilla-minus-one',\n",
       " 'elemental-2023',\n",
       " 'trolls-band-together']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[res['movie_ids'][rec] for rec in top_n_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
